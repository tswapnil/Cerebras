{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "'''Layer Class to Abstract representation of weights '''\n",
    "class Layer():\n",
    "    '''Weights are randomly intialized to floats between [-1 1)'''\n",
    "    def __init__(self,input_layer_width, hidden_layer_width):\n",
    "        self.w = 2*np.random.random((input_layer_width, hidden_layer_width)) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "'''The Main Class that implements various helper methods and the training of the network'''\n",
    "class OilSpill():\n",
    "    '''l1 , l2 , l3 are layers representing weights between Input-Hidden1, Hidden1-Hidden2 and Hidden2 - Output\n",
    "    b2 and b3 are bias unit weights for hidden1 and hidden2 respectively. Neural Net is trained on TrainData and TrainLabelData\n",
    "    And verified on ValidationData - ValidationLabel'''\n",
    "    def __init__(self, N_input, N_hidden_1, N_hidden_2, TrainData, TrainLabelData, ValidationData, ValidationLabel):\n",
    "        self.l1 = Layer(N_input,N_hidden_1)\n",
    "        self.l2 = Layer(N_hidden_1, N_hidden_2)\n",
    "        self.l3 = Layer(N_hidden_2,10)\n",
    "        self.b2 = 1 #bias for hidden1\n",
    "        self.b3 = 1 # bias for hidden2\n",
    "        self.train = TrainData\n",
    "        self.labels = TrainLabelData\n",
    "        self.val = ValidationData\n",
    "        self.valLabels = ValidationLabel\n",
    "    '''helper relu method to find max(0,x)'''   \n",
    "    def _relu(self,x):\n",
    "        if x <0 :\n",
    "            return 0\n",
    "        else :\n",
    "            return x\n",
    "    '''helper method to compute derivative of relu function'''\n",
    "    def _relu_der(self,x):\n",
    "        if x > 0:\n",
    "            return 1;\n",
    "        else :\n",
    "            return 0;\n",
    "    '''helper method to compute sofmax outputs for elements in the array X'''\n",
    "    def SOFTMAX(self, X):\n",
    "        expMat = []\n",
    "        den = 0\n",
    "        for x in X:\n",
    "            t = np.exp(x)\n",
    "            #print(\"x is \" + str(x))\n",
    "            #print(\"t is \" + str(t))\n",
    "            expMat.append(t)\n",
    "            den += t\n",
    "        expMat[:] = [y/den for y in expMat]\n",
    "        return expMat\n",
    "    '''helper method to compute relu activations of array X'''\n",
    "    def RELU(self, X):\n",
    "        temp = []\n",
    "        #print(len(X))\n",
    "        for x in X:\n",
    "            temp.append(self._relu(x))\n",
    "        return temp\n",
    "    '''helper method to compute derivation of relu of array X'''\n",
    "    def RELU_DER(self, X):\n",
    "        temp = []\n",
    "        for x in X:\n",
    "            temp.append(self._relu_der(x))\n",
    "        return temp\n",
    "    ''' method to validate the results by finding misses and hits '''\n",
    "    def _validate(self):\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "        for data,label in zip(self.val,self.valLabels):\n",
    "            \n",
    "            H1_ = (np.dot(data,self.l1.w))\n",
    "            #print(type(H1_))\n",
    "            H1 = self.RELU(H1_)\n",
    "            #print(H1.shape)\n",
    "            \n",
    "            H2_ = (np.dot(H1, self.l2.w))\n",
    "            H2_ = [self.b2 + po for po in H2_]\n",
    "            H2 = self.RELU(H2_)\n",
    "            \n",
    "            O_ = (np.dot(H2,self.l3.w))\n",
    "            O_ = [self.b3 + gp for gp in O_]\n",
    "            O = self.SOFTMAX((O_))\n",
    "            \n",
    "            maxIndex = O.index(max(O))\n",
    "            maxValIndex = label.index(max(label))\n",
    "            if maxIndex == maxValIndex :\n",
    "                hits+=1\n",
    "            else:\n",
    "                misses+=1\n",
    "        print(\"accuracy is \" + str(hits/len(self.val)))\n",
    "        print(\"hits \" + str(hits))\n",
    "    ''' method to perform batch training . Niter = number of iterations, batch_size = size of batch, \n",
    "    lamda = regularization parameter. Calls _epoch that performs batch training over one epoch .'''\n",
    "    def _train(self,eta, Niter, batch_size, lamda):\n",
    "        counter = 0\n",
    "        for i in range(Niter):\n",
    "            self._epoch(eta ,batch_size, lamda)\n",
    "            counter = (counter+1)%10\n",
    "            if(counter == 9) :\n",
    "                self._validate()\n",
    "    ''' trains the neural net for one epoch'''\n",
    "    def _epoch(self,eta, batch_size,lamda):\n",
    "        size = len(self.train)\n",
    "        num_batches = size//batch_size\n",
    "        bs = 0\n",
    "        for i in range(num_batches):\n",
    "            data = self.train[bs:bs+batch_size]\n",
    "            label = self.labels[bs:bs+batch_size]\n",
    "            \n",
    "            a = len(data) #batch size\n",
    "            ActivationMatrix = np.matmul(data,self.l1.w)\n",
    "            \n",
    "            #Hidden1 and Hidden 2 forward pass \n",
    "            H1 = [self.RELU(row_) for row_ in ActivationMatrix]\n",
    "            H2_ = np.matmul(H1, self.l2.w)\n",
    "            H2_ = [[self.b2 + po for po in row_] for row_ in H2_]\n",
    "            H2 = [self.RELU(row_) for row_ in H2_]\n",
    "            \n",
    "            #Forward Pass To Output O \n",
    "            O_ = np.matmul(H2,self.l3.w)\n",
    "            O_ = [[self.b3 + gp for gp in row_] for row_ in O_]\n",
    "            O = [self.SOFTMAX(row_) for row_ in O_]\n",
    "            \n",
    "            # Backward Delta computations - BACKWARD PASS\n",
    "            Del_O = [[l-o for o,l in zip(o_row,l_row)] for o_row,l_row in zip(O,label)] # label is one hot\n",
    "            # Batch size X N(O)\n",
    "            #Weights update for Layer 3\n",
    "            self.l3.w = (1-2*lamda)*self.l3.w + eta*(np.matmul(np.transpose(H2),Del_O))\n",
    "            \n",
    "            H2_prime = [self.RELU_DER(row_) for row_ in H2]\n",
    "            \n",
    "            # Second Last layer weights delta\n",
    "            Del_H2 = np.multiply(np.matmul(self.l3.w,np.transpose(Del_O)),np.transpose(H2_prime))\n",
    "            # N(H2) X Batch Size\n",
    "            E_1 = np.matmul(Del_H2,H1)\n",
    "            # N(H2) X N(H1)\n",
    "            # Weights Update for layer 2\n",
    "            self.l2.w = (1-2*lamda)*self.l2.w + eta*np.transpose(E_1)\n",
    "            \n",
    "            H1_prime = [self.RELU_DER(row_) for row_ in H1]\n",
    "            \n",
    "            #Hidden1 Delta Computations\n",
    "            Del_H1 = np.multiply(np.matmul(self.l2.w,Del_H2),np.transpose(H1_prime))\n",
    "            #N(H1) X Batch\n",
    "            E_2 = np.matmul(Del_H1,data)\n",
    "            # Weights update for layer 1\n",
    "            self.l1.w = (1-2*lamda)*self.l1.w + eta*np.transpose(E_2)\n",
    "            \n",
    "            loss = sum(sum(np.multiply(label,O)))\n",
    "           \n",
    "            # Bias Update for layer 2\n",
    "                        \n",
    "            (p,b) = self.l2.w.shape\n",
    "            for j in range(b):\n",
    "                self.b2 += eta*sum([Del_H2[j][k] for k in range(len(data))])\n",
    "            \n",
    "            # Bias update last layer\n",
    "            (p,b) = self.l3.w.shape\n",
    "            for j in range(b):\n",
    "                self.b3 += eta*sum([Del_O[k][j] for k in range(len(data))]) \n",
    "            \n",
    "            #batch index update    \n",
    "            bs = bs + batch_size\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "'''Unit testing '''\n",
    "class TestOilSpill(unittest.TestCase):\n",
    "    '''Build up OilSpill Object'''\n",
    "    def setUp(self):\n",
    "        self.train = [[1,2,3,4,5],[6,7,8,9,10]]\n",
    "        self.labels = [[0,0,1,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,1]]\n",
    "        self.val = [[11,1,1,14,5],[1,2,5,6,2]]\n",
    "        self.valLab = [[0,0,0,0,0,0,0,0,0,1],[0,0,0,0,0,0,1,0,0,0]]\n",
    "        self.testObj = OilSpill(5,2,1,self.train,self.labels,self.val,self.valLab)\n",
    "        pass\n",
    "    '''Tests whether the size of the layers are correct'''\n",
    "    def testLayerSize(self):\n",
    "        (x1,y1) = self.testObj.l1.w.shape\n",
    "        (x2,y2) = self.testObj.l2.w.shape\n",
    "        (x3,y3) = self.testObj.l3.w.shape\n",
    "        self.assertEqual(x1,5)\n",
    "        self.assertEqual(y1,2)\n",
    "        self.assertEqual(x2,2)\n",
    "        self.assertEqual(y2,1)\n",
    "        self.assertEqual(x3,1)\n",
    "        self.assertEqual(y3,10)\n",
    "    '''Tests the relu helper function'''\n",
    "    def testRelu(self):\n",
    "        self.assertEqual(self.testObj._relu(-5),max(0,-5))\n",
    "        self.assertEqual(self.testObj._relu(15),max(0,15))\n",
    "    '''tests Relu Der function'''\n",
    "    def testReluDer(self):\n",
    "        self.assertEqual(self.testObj._relu_der(-5),0)\n",
    "        self.assertEqual(self.testObj._relu_der(15),1)\n",
    "    ''' Tests the function SOFTMAX'''\n",
    "    def testSOFTMAX(self):\n",
    "        self.assertEqual(self.testObj.SOFTMAX([2,0]),[np.exp(2)/(1 + np.exp(2)) , 1 / (1+np.exp(2))])\n",
    "    ''' Tests helper method RELU'''\n",
    "    def testRELU(self):\n",
    "        self.assertEqual(self.testObj.RELU([-5,4,120,-90]),[0,4,120,0])\n",
    "    ''' Tests helper method RELU_DER'''\n",
    "    def testRELU_DER(self):\n",
    "        self.assertEqual(self.testObj.RELU_DER([-4.1,4.9,95,-0]),[0,1,1,0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Script to easily replicate results '''\n",
    "class Executor():\n",
    "    def __init__(self):\n",
    "        self.trainData = []\n",
    "        self.labels = []\n",
    "        self.val = []\n",
    "        self.valLabels = []\n",
    "        self.csvTrainData = self._readCsv_('C:\\\\Users\\\\tanej\\\\Downloads\\\\cerebras_\\\\mnist_train.csv')\n",
    "        self.csvTestData = self._readCsv_('C:\\\\Users\\\\tanej\\\\Downloads\\\\cerebras_\\\\mnist_test.csv')\n",
    "        self.buildData()\n",
    "    '''Preprocess csvData to prepare TrainData and TestData'''\n",
    "    def buildData(self):\n",
    "        for data in self.csvTrainData:\n",
    "            trow = [1.0] + [float(r) for r in data[1:]]\n",
    "            mean = sum(trow)/len(trow)\n",
    "            # SUBTRACTING MEAN AND NORMALIZING INPUT\n",
    "            row = [(tr-mean) for tr in trow]\n",
    "            self.trainData.append(self._normalize(row))\n",
    "            temp = [0]*10\n",
    "            #ONE HOT ENCODING OF LABELS\n",
    "            temp[int(data[0])] = 1\n",
    "            self.labels.append(temp)\n",
    "        for data in self.csvTestData:\n",
    "            trow = [1.0] + [float(r) for r in data[1:]]\n",
    "            mean = sum(trow)/len(trow)\n",
    "            # SUBTRACTING MEAN AND NORMALIZING INPUT\n",
    "            row = [(tr-mean) for tr in trow]\n",
    "            self.val.append(self._normalize(row))\n",
    "            temp = [0]*10\n",
    "            #ONE HOT ENCODING OF LABELS\n",
    "            temp[int(data[0])] = 1\n",
    "            self.valLabels.append(temp)\n",
    "    '''reads CSV file and shuffles the input'''\n",
    "    def _readCsv_(self, fileName):\n",
    "        import csv\n",
    "        trainFile = open(fileName,'r')\n",
    "        csvReader = csv.reader(trainFile)\n",
    "        csvData = []\n",
    "        for row in csvReader:\n",
    "            csvData.append(row)\n",
    "        from random import shuffle\n",
    "        shuffle(csvData)\n",
    "        return csvData\n",
    "    ''' normalizes the input '''\n",
    "    def _normalize(self,v):\n",
    "        norm = np.linalg.norm(v)\n",
    "        if norm == 0: \n",
    "            return v\n",
    "        return v / norm\n",
    "    '''Preprocess csvData to separate training data and validation data'''\n",
    "    def _preprocess_(self):\n",
    "        for data in self.csvTrainData:\n",
    "            trow = [1.0] + [float(r) for r in data[1:]]\n",
    "            mean = sum(trow)/len(trow)\n",
    "            # SUBTRACTING MEAN AND NORMALIZING INPUT\n",
    "            row = [(tr-mean) for tr in trow]\n",
    "            self.trainData.append(self._normalize(row))\n",
    "            temp = [0]*10\n",
    "            #ONE HOT ENCODING OF LABELS\n",
    "            temp[int(data[0])] = 1\n",
    "            self.labels.append(temp)\n",
    "    def __main__(self):\n",
    "        oilSpill= OilSpill(785,100,110,self.trainData,self.labels,self.val,self.valLabels)\n",
    "        oilSpill._train(0.001,123, 14,0.00001)\n",
    "    def __validate__(self):\n",
    "        self._preprocess_()\n",
    "        #Reduce DataSet for checking\n",
    "        train = self.trainData[:20101]\n",
    "        trainLab = self.labels[:20101]\n",
    "        valid = self.trainData[50000:]\n",
    "        validLab = self.labels[50000:]\n",
    "        \n",
    "        oilSpill= OilSpill(785,100,110,train,trainLab,valid[:500],validLab[:500])\n",
    "        oilSpill._train(0.001,123, 14,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "executorObj = Executor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9481\n",
      "hits 9481\n",
      "accuracy is 0.9556\n",
      "hits 9556\n",
      "accuracy is 0.9595\n",
      "hits 9595\n",
      "accuracy is 0.9608\n",
      "hits 9608\n",
      "accuracy is 0.9624\n",
      "hits 9624\n",
      "accuracy is 0.9636\n",
      "hits 9636\n",
      "accuracy is 0.9643\n",
      "hits 9643\n",
      "accuracy is 0.9648\n",
      "hits 9648\n",
      "accuracy is 0.9647\n",
      "hits 9647\n",
      "accuracy is 0.9652\n",
      "hits 9652\n",
      "accuracy is 0.9658\n",
      "hits 9658\n",
      "accuracy is 0.9655\n",
      "hits 9655\n"
     ]
    }
   ],
   "source": [
    "executorObj.__main__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.91\n",
      "hits 455\n",
      "accuracy is 0.936\n",
      "hits 468\n",
      "accuracy is 0.946\n",
      "hits 473\n",
      "accuracy is 0.952\n",
      "hits 476\n",
      "accuracy is 0.956\n",
      "hits 478\n",
      "accuracy is 0.954\n",
      "hits 477\n",
      "accuracy is 0.954\n",
      "hits 477\n",
      "accuracy is 0.954\n",
      "hits 477\n",
      "accuracy is 0.954\n",
      "hits 477\n",
      "accuracy is 0.956\n",
      "hits 478\n",
      "accuracy is 0.958\n",
      "hits 479\n",
      "accuracy is 0.958\n",
      "hits 479\n"
     ]
    }
   ],
   "source": [
    "executorObj.__validate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oilSpill._train(0.001,12300, 14,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proj]",
   "language": "python",
   "name": "conda-env-proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
